### **The spelled-out intro to neural networks and backpropagation: building micrograd**

Backpropagation: orqaga tarqalish

Backpropagation helps neural networks learn by providing a systematic way to improve their predictions through error correction. Here‚Äôs how it works:

- When a neural network makes a prediction, it compares the prediction to the actual answer using a loss function, which measures how far off the prediction was[1](https://www.ibm.com/think/topics/backpropagation)[5](https://www.grammarly.com/blog/ai/what-is-backpropagation/)[6](https://wandb.ai/mostafaibrahim17/ml-articles/reports/Decoding-Backpropagation-and-Its-Role-in-Neural-Network-Learning--Vmlldzo3MTY5MzM1).
- The network then calculates how much each part (weight) of the network contributed to the error. This is done by sending the error backward through the network, from the output layer to the input layer, using the chain rule from calculus[1](https://www.ibm.com/think/topics/backpropagation)[5](https://www.grammarly.com/blog/ai/what-is-backpropagation/).
- As the error is sent backward, the network computes gradients-these are signals that tell each weight how it should be adjusted to reduce the error next time[1](https://www.ibm.com/think/topics/backpropagation)[2](https://builtin.com/machine-learning/backpropagation-neural-network)[5](https://www.grammarly.com/blog/ai/what-is-backpropagation/).
- The network then updates its weights in the direction that will decrease the error, using an optimization algorithm like gradient descent[1](https://www.ibm.com/think/topics/backpropagation)[5](https://www.grammarly.com/blog/ai/what-is-backpropagation/)[6](https://wandb.ai/mostafaibrahim17/ml-articles/reports/Decoding-Backpropagation-and-Its-Role-in-Neural-Network-Learning--Vmlldzo3MTY5MzM1).

By repeating this process for many examples, the neural network gradually learns the best set of weights to make more accurate predictions. Backpropagation is crucial because it allows the network to efficiently identify and correct mistakes, enabling it to learn complex patterns and generalize well to new data

arbitary: o'zboshimchalik bilan, zo'ravon

tensor:

- flexible, multi-dimensional array of numbers that can represent simple or very complex data and relationships

Derivative: hosila

derive: hosil qilish, olmoq

------------------------------
segmentation - division into separate parts or sections

benchmark - a standard or point of reference against which things may be compared or assessed

convolution - a thing that is complex and difficult to follow. a function derived from two given functions by integration which expresses how the shape of one is modified by the other.


### **Lecture 2 | Image Classification**

pipeline - quvur liniyasi

notion - tushuncha, fikr, g‚Äôoya

obvious - aniq, ravshan

Image classigication: a core task in computer vision

First step to detect cat from image:

1. Detect edges: not very scalable to approach
2. Data driven approach:
    1. collect a dataset of images and labels
    2. use machine learning to train a classifier
    3. evaluate the classifier on new images

First classifier: Nearest Neighbor

Example Dataset: CIFAR10

- 10 classes
- 50000 training images
- 10000 testing images

Distance metric to compare images: L1 distance

Time:

- Train O(1)
- Predict O(N)

K in K-nearest neighbors - need to choose more than a for more smooth result

k, distance is hyperparameters

Cross-Validation: Split data into folds, try each fold as validation and average the results

k-nearest:

- very slow at test time
- distance metrics on pixels are not informative

Linear Classification

Basic block of deep neural networks

W - parameters or weights
-------------------------------------------

üì∑ Image Classification
Image classification is the task of assigning a category label to an image (e.g., ‚Äúdog‚Äù or ‚Äúairplane‚Äù). 
Each image is usually represented as a high-dimensional vector (e.g., pixel values), 
and the goal is to learn a function that maps these vectors to labels.

------------------------
üìà Linear Classifiers
Linear classifiers are a family of models that make predictions based on a linear combination of the input features. 
In mathematical terms, for an input image vector x, the model computes:

ùëì(ùë•)=ùëäùë•+ùëèf(x)=Wx+b

Where:
W is a weight matrix
b is a bias vector
The output f(x) is a score for each class
The class with the highest score is predicted.
----------------------------


